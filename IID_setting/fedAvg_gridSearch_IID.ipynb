{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-publicity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "DEVICE = 'GPU'\n",
    "numWorkers = len(tf.config.list_physical_devices('GPU'))\n",
    "if numWorkers == 0:\n",
    "    DEVICE = 'CPU'\n",
    "    numWorkers = !cat /proc/cpuinfo | grep processor | wc -l\n",
    "    numWorkers = int(numWorkers[0])\n",
    "    \n",
    "print(numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import collections\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import talos\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from dataset_loader import load_tf_dataset\n",
    "from models_keras import get_model\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-danger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomSplitClientsData(data, labels, ds_info):\n",
    "    \n",
    "    numParties = ds_info['num_clients']\n",
    "    sample_height, sample_width, sample_channels = ds_info['sample_shape']\n",
    "    num_classes = ds_info['num_classes']\n",
    "    \n",
    "    numSamplesPerClient = int(data.shape[0]/numParties)\n",
    "    #print(numSamplesPerClient)\n",
    "    clientsData = np.zeros((numParties,int(numSamplesPerClient),sample_height,sample_width,sample_channels))\n",
    "    clientsDataLabels = np.zeros((numParties,int(numSamplesPerClient),num_classes))\n",
    "    #print(numSamplesPerClient)\n",
    "    ind = 0\n",
    "    for i in range(numParties):\n",
    "        clientsData[i] = data[ind:ind+numSamplesPerClient]\n",
    "        clientsDataLabels[i]=labels[ind:ind+numSamplesPerClient]\n",
    "        ind = ind+numSamplesPerClient\n",
    "    return clientsData, clientsDataLabels\n",
    "\n",
    "def prepare_data_for_X_clients(x_train, y_train, ds_info):\n",
    "    clientsData, clientsDataLabels = randomSplitClientsData(x_train, y_train, ds_info)\n",
    "    return clientsData, clientsDataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history, params):\n",
    "    print('##########################################################')\n",
    "    print(params)\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('MSE')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    #filename = sys.argv[0].split('/')[-1]\n",
    "    #pyplot.savefig(filename + '_plot.png')\n",
    "    #pyplot.close()\n",
    "    plt.show()\n",
    "    print('##########################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(x_train, y_train, x_val, y_val, params):\n",
    "        \n",
    "    \n",
    "    optimizer = SGD(learning_rate=params['learn_rate'], momentum=params['momentum'], nesterov=False, name='SGD')\n",
    "    \n",
    "    model = get_model(params, ds_info)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"mean_squared_error\",\n",
    "                  metrics=['accuracy', tf.keras.metrics.Recall(),tf.keras.metrics.Precision()],\n",
    "                  run_eagerly=False)\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                                  min_delta=0.01,\n",
    "                                                  patience=5)\n",
    "    history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    callbacks=[early_stop],\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=0)\n",
    "\n",
    "    hist.append(history)\n",
    "    hist_params.append(params)\n",
    "        \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_gridsearch(work):\n",
    "    \n",
    "    client_number, clientData, clientDataLabels, param_grid = work\n",
    "    \n",
    "    free = np.where(workers == 1)\n",
    "    i = free[0][0]\n",
    "    workers[i] = 0\n",
    "\n",
    "    #Distribute load accross DEVICEs\n",
    "    with tf.device(f\"/{DEVICE}:{i}\"):\n",
    "        print(f\"training on {DEVICE}: {i}\")\n",
    "\n",
    "        scan_results = talos.Scan(x=clientData,\n",
    "                                  y=clientDataLabels,\n",
    "                                  params=param_grid,\n",
    "                                  model=experiment,\n",
    "                                  experiment_name=f\"{experiment_name}_{client_number}\")\n",
    "        scan_res[client_number]=scan_results\n",
    "        print(f\"client running on {DEVICE}: {i} finished\")\n",
    "\n",
    "        workers[i] = 1\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "def grid_search_for_X_clients(numClients, clientsData, clientsDataLabels, param_grid):\n",
    "    \n",
    "    global scan_res\n",
    "    global workers\n",
    "    \n",
    "    scan_res = np.zeros(numClients, dtype=object)\n",
    "    workers = np.ones(numWorkers)\n",
    "    \n",
    "    global hist\n",
    "    global hist_params\n",
    "    hist = []\n",
    "    hist_params = []\n",
    "                \n",
    "    work = [(i, clientsData[i], clientsDataLabels[i], deepcopy(param_grid)) for i in range(numClients)]\n",
    "    \n",
    "    with ThreadPool(len(workers)) as p:\n",
    "        p.map(client_gridsearch, work)\n",
    "\n",
    "    return scan_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_test_metrics(work):\n",
    "    \n",
    "        client_number, clientData, clientDataLabels, avg_test_params = work\n",
    "    \n",
    "        free = np.where(workers == 1)\n",
    "        i = free[0][0]\n",
    "        workers[i] = 0\n",
    "    \n",
    "        #Distribute load accross DEVICEs\n",
    "        with tf.device(f\"/{DEVICE}:{i%numWorkers}\"):\n",
    "            \n",
    "            print(f\"training on {DEVICE}: {i}\")\n",
    "            model = get_model(avg_test_params, ds_info)\n",
    "            optimizer = SGD(learning_rate=avg_test_params['learn_rate'], momentum=avg_test_params['momentum'], nesterov=False, name='SGD')\n",
    "            model.compile(optimizer=optimizer, loss=\"mean_squared_error\", metrics=['accuracy',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "\n",
    "            \n",
    "            model.fit(x=clientData,\n",
    "                        y=clientDataLabels,\n",
    "                        epochs=avg_test_params['epochs'],\n",
    "                        batch_size=avg_test_params['batch_size'],\n",
    "                        verbose=0)\n",
    "                        \n",
    "            print(f\"client running on {DEVICE}: {i} finished\")\n",
    "            metrics = model.evaluate(x_test, y_test)\n",
    "            metrics_res[client_number] = metrics\n",
    "            \n",
    "            workers[i] = 1\n",
    "            \n",
    "            \n",
    "        return\n",
    "\n",
    "def test_metrics_for_X_clients(numClients, clientsData, clientsDataLabels, avg_test_params):\n",
    "\n",
    "    global metrics_res\n",
    "    global workers\n",
    "    \n",
    "    metrics_res = np.zeros(numClients, dtype=object)   \n",
    "    workers = np.ones(numWorkers)\n",
    "                \n",
    "    work = [(i, clientsData[i], clientsDataLabels[i], avg_test_params) for i in range(numClients)]\n",
    "    \n",
    "    with ThreadPool(len(workers)) as p:\n",
    "        p.map(client_test_metrics, work)\n",
    "    \n",
    "    return metrics_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(params, ds, test_split, ds_info):\n",
    "    \n",
    "    numClients = ds_info['num_clients']\n",
    "    \n",
    "    (x_train, y_train) = ds\n",
    "    \n",
    "    global x_test\n",
    "    global y_test\n",
    "    (x_test, y_test) = test_split\n",
    "    \n",
    "    Path(experiment_name+\"_res/res\"+str(numClients)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    clientsData, clientsDataLabels = prepare_data_for_X_clients(x_train, y_train, ds_info)\n",
    "\n",
    "    big_res = []\n",
    "\n",
    "    res = grid_search_for_X_clients(numClients, clientsData, clientsDataLabels, params)\n",
    "\n",
    "    big_res=res\n",
    "\n",
    "    ## Sort dataframes\n",
    "    sorted_data = []\n",
    "    big_res = [r for r in big_res if not r == 0]\n",
    "\n",
    "    for _,df in enumerate(big_res):\n",
    "        sorted_data.append(df.data.sort_values(by='val_accuracy',ascending=False).head())\n",
    "\n",
    "    ## Write dataframes to files\n",
    "    for i,df in enumerate(sorted_data):\n",
    "        df.to_csv(experiment_name+\"_res/res\"+str(numClients)+\"/res\"+str(numClients)+\"_client_\"+str(i)+\".csv\")\n",
    "\n",
    "    #for i in range(len(sorted_data)):\n",
    "        #with pandas.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            #display(sorted_data[i])\n",
    "\n",
    "    avg_params = np.zeros(4, dtype=float) #[lr, batchsize, epochs, momentum]\n",
    "\n",
    "    for _,client_data in enumerate(sorted_data):\n",
    "        avg_params[0] += client_data.head(1)['learn_rate'].item()\n",
    "        avg_params[1] += client_data.head(1)['batch_size'].item()\n",
    "        avg_params[2] += client_data.head(1)['round_epochs'].item()\n",
    "        avg_params[3] += client_data.head(1)['momentum'].item()\n",
    "\n",
    "    avg_params = avg_params / len(sorted_data)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Avg lr:\", avg_params[0], \"Avg batchsize:\", int(math.ceil(avg_params[1])), \"Avg epochs:\", int(math.ceil(avg_params[2])), \"Avg momentum:\",avg_params[3])\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    #summarize_diagnostics(hist[0], hist_params[0])\n",
    "\n",
    "    ####### Retrain each client to run the test set and get best metrics\n",
    "    avg_test_params = dict(learn_rate=avg_params[0], batch_size=int(math.ceil(avg_params[1])), epochs=int(math.ceil(avg_params[2])), act_fn='relu', momentum=avg_params[3])\n",
    "    avg_test_res = []\n",
    "\n",
    "    clientsData, clientsDataLabels = prepare_data_for_X_clients(x_train, y_train, ds_info)\n",
    "\n",
    "    res = test_metrics_for_X_clients(numClients, clientsData, clientsDataLabels, avg_test_params)\n",
    "\n",
    "    avg_test_res=res\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_recall = 0.0\n",
    "\n",
    "    avg_test_res = [r for r in avg_test_res if not r == 0]\n",
    "\n",
    "    for _,client_metrics in enumerate(avg_test_res):\n",
    "        if client_metrics[1] >= best_val_acc:\n",
    "            best_val_acc = client_metrics[1]\n",
    "            best_precision = client_metrics[2]\n",
    "            best_recall = client_metrics[3]\n",
    "\n",
    "    print(\"Best val_acc: \", best_val_acc)\n",
    "    print(\"Best precision: \", best_precision)\n",
    "    print(\"Best recall: \", best_recall)\n",
    "\n",
    "\n",
    "    ####### Activation functions optimization\n",
    "    act_fn = [\"relu\", \"sigmoid\", \"tanh\"]\n",
    "    act_fn_params = dict(learn_rate=[avg_params[0]], batch_size=[int(math.ceil(avg_params[1]))], epochs=[int(math.ceil(avg_params[2]))],momentum=[avg_params[3]], act_fn=act_fn)\n",
    "\n",
    "    clientsData, clientsDataLabels = prepare_data_for_X_clients(x_train, y_train, ds_info)\n",
    "\n",
    "    res = grid_search_for_X_clients(numClients, clientsData, clientsDataLabels, act_fn_params)\n",
    "\n",
    "    act_big_res=res\n",
    "\n",
    "    ## Sort dataframes\n",
    "    act_big_res = [r for r in act_big_res if not r == 0]\n",
    "    sorted_data_activation = []\n",
    "    for _,df in enumerate(act_big_res):\n",
    "        sorted_data_activation.append(df.data.sort_values(by='val_accuracy',ascending=False))\n",
    "\n",
    "    for i in range(len(sorted_data_activation)):\n",
    "        with pandas.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            display(sorted_data_activation[i])\n",
    "\n",
    "    ## Get best activation function\n",
    "    act_fn_count = np.zeros(len(act_fn), dtype=float)\n",
    "\n",
    "    for _,client_data in enumerate(sorted_data_activation):\n",
    "        for i,fn in enumerate(act_fn):\n",
    "            if client_data.head(1)['act_fn'].item() == fn:\n",
    "                act_fn_count[i] += 1\n",
    "\n",
    "    best_act_fn = act_fn[np.argmax(act_fn_count)]\n",
    "    print(\"Best activation function :\", best_act_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-blocking",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_name = 'svhn_cropped'\n",
    "experiment_name = f\"{dataset_name}_iid\"\n",
    "\n",
    "# define the grid search parameters\n",
    "params = dict(act_fn = [\"relu\"],\n",
    "              batch_size = [64],#[32,16,8,4,2]#[32,64,128]#[8,16,32]#[256,128,64,32]\n",
    "              epochs = [125],#[75,125]\n",
    "              learn_rate = [0.1],#[0.1,0.15,0.2,0.25,0.3]#[0.08, 0.1, 0.2, 0.3]#[0.001,0.01, 0.1]\n",
    "              momentum = [0.9])\n",
    "\n",
    "ds, test_split, ds_info = load_tf_dataset(dataset_name=dataset_name, decentralized=True, display=True)\n",
    "ds_info['num_clients'] = 10\n",
    "run(params, ds, test_split, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48c118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
